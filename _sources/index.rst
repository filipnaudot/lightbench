lightbench documentation
========================

Welcome to the **lightbench** documentation!

This site contains developer and user documentation for the **lightbench** library.
You can find the source code and contribute on GitHub:

ðŸ”— `lightbench GitHub repository <https://github.com/filipnaudot/lightbench/>`_


Project motivation
------------------
**lightbench** is a benchmarking framework built to make task-specific evaluation of large language models (LLMs) 
simple, fast, and accessible. 

As LLMs grow more capable and versatile, they're being applied across an increasingly 
wide range of domains and tasks. However, this versatility also makes it harder to determine which model is best suited
for a specific use case, especially when niche capabilities or specialized data are involved.

Not all LLMs perform equally well across all tasks. Just because a model excels in one area doesn't mean it's 
the right choice for another. **lightbench** helps bridge that gap by providing a streamlined way to compare and evaluate 
models in the context that actually matters: *your task*, *your data*, *your domain*.



.. toctree::
   :caption: Contents
   :hidden:
   :maxdepth: 2

   lightbench.loaders
   lightbench.metrics
   lightbench.utils
   lightbench.evaluators